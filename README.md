# Used_Cars_Prediction_Using_ML
This project aims to predict the prices of used cars using linear regression and polynomial regression models. 
The dataset used in this project contains information about various factors such as make, model, fuel type, location, color, owner, seller type etc which can potentially influence the price of a used car.
# Dataset
The dataset used for this project contains the following columns:
1. Make: The brand or manufacturer of the car.
2. Model: The model of the car.
3. Year: Manufacturing year of the car.
4. Kilometer: Kilometer driven by the car.
5. Fuel Type: The type of fuel used by the car (e.g., petrol, diesel).
6. Transmission: It refers to the mechanism that transfers power from the engine to the wheels, allowing the driver to control the speed and direction of the vehicle.
7. Location: The location where the car is being sold.
8. Color: The color of the car.
9. Owner: The number of previous owners of the car.
10. Seller Type: The type of seller (e.g., individual, dealer).
11. Engine: It represents the total volume of all the cylinders in the engine.
12. Max Power: Maximum power of the car given in bhp.
13. Max Torque: Maximum torque generated by the car.
14. Drivetrain: It refers the system that transfers power from the engine to the wheels, enabling the vehicle to move.
15. Length: Length of the car.
16. Width: Width of the car.
17. Height: Height of the car.
18. Seating Capacity: Total seats in the car.
19. Fuel Tank Capacity: Fuel tank capacity in liters.
20. Price: The target variable, representing the price of the used car.
# Dependencies
The following dependencies are required to run the code:
1. Python 3.0 or above
2. Pandas
3. NumPy
4. Scikit-learn
5. Statsmodels
6. Matplotlib
# Usage
- Ensure that you have the dataset available in the project directory. (available in reposatory)
- Open the Jupyter Notebook or Python IDE of your choice.
- Open the "used_cars_price_prediction.ipynb" file.
- Run the notebook cell by cell to execute the code and see the results.
# Models and Evaluation
- This project includes regression models: linear regression. The models are trained and evaluated as follows:
- Data preprocessing: The "Seating Capacity" column exhibit a significant imbalance in their distribution, indicating a disproportionate representation of certain categories compared to others. Due to this severe imbalance, it might be appropriate to remove these column from the analysis to prevent potential biases or misleading conclusions. The relationship between the "Height", "Seating Capacity", "rpm" and "rpm_t" with "Price" columns does not exhibit a clear correlation or trend. There seems to be no significant relationship between the height of a car and its price, so it might be appropriate to remove these columns from the analysis. The "Seller Type" column exhibit a significant imbalance in their distribution, indicating a disproportionate representation of certain categories compared to others. Due to this severe imbalance, it might be appropriate to remove these column from the analysis to prevent potential biases or misleading conclusions. Based on the analysis of the dataset, it can be observed that the variables "Max Power," "Torque," and "Engine" are highly correlated with each other, with a correlation coefficient of more than 80%. Additionally, it is found that "Max Power" exhibits a higher correlation with the target variable compared to "Torque" and "Engine." Therefore, it is recommended to keep only the "Max Power" variable and remove "Torque" and "Engine" from the dataset. The variables "Length", "Width", and "Fuel Tank Capacity" are highly correlated with each other, with a correlation coefficient of more than 80%. The "Fuel Tank Capacity" exhibits a higher correlation with the target variable compared to "Length" and "Width". Hence we keep "Fuel Tank Capacity" and remove "Length" & "Width" variables from the dataset.
- Train-Test Split: The dataset is split into training and testing sets using the train_test_split function from Scikit-learn.
- Transformation: The columns "Max Power" and "Fuel Tank Capacity" contain missing values. To handle these missing values, it is recommended to use a simple imputer technique. This technique replaces the missing values with a suitable measure such as the mean, median, or most frequent value of the respective column. The columns "Make," "Fuel Type," "Transmission," "Location," and "Drivetrain" are nominal categorical variables, while the "Owner" column is an ordinal categorical variable. To encode these categorical variables, it is suggested to use One Hot Encoding for the nominal variables and Ordinal Encoder for the ordinal variable. The variables "Year," "Kilometer," "Max Power," and "Fuel Tank Capacity" are found to have a distribution that is not normally distributed. In such cases, it is advisable to apply a transformation to make the distribution more Gaussian-like. One possible transformation method is the Yeo-Johnson transform, which can handle both positive and negative values. By applying the Yeo-Johnson transform, the variables' distribution can be brought closer to a normal distribution
- Linear Regression: A linear regression model is fitted to the training data and evaluated using metrics such as R-squared score. The model is then used to predict car prices on the testing data.
# Conclusion
- The linear regression model performed reasonably well with an R-squared score of 84% on the test dataset. This indicates that approximately 84% of the variability in the target variable can be explained by the linear relationship with the predictor variables.
- Furthermore, during training, the Ordinary Least Squares (OLS) algorithm achieved a training result of 81%. The OLS algorithm is commonly used for linear regression and aims to minimize the sum of squared residuals, providing estimates for the coefficients of the linear model.
-These results suggest that the linear regression model is able to capture a significant portion of the underlying patterns and relationships in the data. The model's ability to generalize well to unseen data, as indicated by the test R-squared score, indicates that it is not overfitting and can be considered reasonably robust.
